{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bgpEAXtPEjZV"
      },
      "source": [
        "# Final Project - Introduction to Machine Learning (CS680)\n",
        "## Evaluating the Use of Fast Adversarial Training in Defending Against Adversarial Patch Attacks\n",
        "### Pedro Maia de Sampaio Ferraz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQVKGMWwE5Pc"
      },
      "source": [
        "### Clone FAST-BAT repo and train models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iF886GzpT7J"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/NormalUhr/FastBAT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBOeaHwWpvJv"
      },
      "outputs": [],
      "source": [
        "%cd /content/FastBAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACbBGvj7pga8"
      },
      "outputs": [],
      "source": [
        "# Regular model\n",
        "!python train.py \\\n",
        "    --mode pgd \\\n",
        "    --dataset CIFAR10 \\\n",
        "    --attack_step 0 \\\n",
        "    --lr_scheduler multistep \\\n",
        "    --lr_max 0.1 \\\n",
        "    --dataset_val_ratio 0.01\n",
        "\n",
        "# FAST-BAT model\n",
        "!python train.py \\\n",
        "    --mode fast_bat \\\n",
        "    --dataset CIFAR10 \\\n",
        "    --attack_eps 8 \\\n",
        "    --attack_step_test 10 \\\n",
        "    --dataset_val_ratio 0.01\n",
        "\n",
        "# # FAST-AT model\n",
        "!python train.py \\\n",
        "    --mode fast_at \\\n",
        "    --dataset CIFAR10 \\\n",
        "    --attack_eps 8 \\\n",
        "    --attack_step_test 10 \\\n",
        "    --dataset_val_ratio 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52pu1n6KPPgW"
      },
      "source": [
        "### Define methods for training adversarial patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47p2_H-xj-hf"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import tqdm as tqdm\n",
        "from torch import autograd\n",
        "from torchvision import transforms\n",
        "from datasets import *\n",
        "from model_zoo import *\n",
        "from torch.nn.modules.utils import _pair, _quadruple\n",
        "\n",
        "class PatchTransformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PatchTransformer, self).__init__()\n",
        "\n",
        "    def forward(self, adv_patch, img_size, batch_size, type=\"random\"):\n",
        "        # Determine size of padding\n",
        "        pad_size = (img_size - adv_patch.size(-1))\n",
        "\n",
        "        # Expand patch to create batch_size patches\n",
        "        adv_patch = adv_patch.expand(batch_size, *adv_patch.shape)\n",
        "        padded_adv_patch_ext = torch.zeros(batch_size, 3, img_size, img_size).cuda()\n",
        "\n",
        "        # Clamp patch\n",
        "        adv_patch = torch.clamp(adv_patch, 0.000001, 0.999999)\n",
        "\n",
        "        # Pad to get image size\n",
        "        pad_dims = torch.randint(pad_size, (batch_size, 2,))\n",
        "\n",
        "        if type == \"corner\":\n",
        "            pad_func = nn.ConstantPad2d((0, pad_size, 0, pad_size), 0)\n",
        "            adv_patch = pad_func(adv_patch)\n",
        "            return adv_patch\n",
        "        elif type == \"random\":\n",
        "            for i in range(pad_dims.shape[0]):\n",
        "                pad_func = nn.ConstantPad2d((pad_dims[i][0],pad_size-pad_dims[i][0],pad_dims[i][1],pad_size-pad_dims[i][1]), 0)\n",
        "                padded_adv_patch_ext[i] = pad_func(adv_patch[i])\n",
        "            return padded_adv_patch_ext\n",
        "        \n",
        "        return adv_patch\n",
        "\n",
        "class PatchApplier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PatchApplier, self).__init__()\n",
        "\n",
        "    def forward(self, img, adv_patch):\n",
        "        img = torch.where((adv_patch == 0), img, adv_patch)\n",
        "        return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srvI3zpjds0q"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "class PatchTrainer(object):\n",
        "    def __init__(self, patch_size, model_path, device):\n",
        "        train_dl, val_dl, test_dl, norm_layer, num_classes = cifar10_dataloader(data_dir=\"./data/\",\n",
        "                                                                                batch_size=200,\n",
        "                                                                                val_ratio=0.2)\n",
        "        self.patch_size = patch_size\n",
        "        self.batch_size = 200\n",
        "        self.img_size = 32\n",
        "        self.train_dl = train_dl\n",
        "        self.val_dl = val_dl\n",
        "        self.test_dl = test_dl\n",
        "        self.epoch_length = len(train_dl)\n",
        "        self.model = PreActResNet18(num_classes=num_classes, activation_fn=nn.ReLU)\n",
        "        self.model.normalize = norm_layer\n",
        "        self.model.load_state_dict(torch.load(model_path, map_location=torch.device(device)))\n",
        "        self.model = self.model.eval().cuda()\n",
        "        self.patch_applier = PatchApplier().cuda()\n",
        "        self.patch_transformer = PatchTransformer().cuda()\n",
        "\n",
        "    def generate_patch(self, type):\n",
        "        if type == 'gray':\n",
        "            adv_patch_cpu = torch.full((3, self.patch_size, self.patch_size), 0.5)\n",
        "        elif type == 'random':\n",
        "            adv_patch_cpu = torch.rand((3, self.patch_size, self.patch_size))\n",
        "        elif type == 'transparent':\n",
        "            adv_patch_cpu = torch.full((3, self.patch_size, self.patch_size), 0.0)\n",
        "\n",
        "        return adv_patch_cpu\n",
        "\n",
        "    def train(self):\n",
        "        n_epochs = 1\n",
        "\n",
        "        adv_patch_cpu = self.generate_patch(\"gray\")\n",
        "        adv_patch_cpu.requires_grad_(True)\n",
        "        optimizer = optim.Adam([adv_patch_cpu], lr=0.05, amsgrad=True)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=50)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        no_patch = self.generate_patch(\"transparent\")\n",
        "        initial_accuracy = self.validate(no_patch)\n",
        "        print(f\"Baseline accuracy: {initial_accuracy}\")\n",
        "\n",
        "        loss_list = []\n",
        "        val_acc_list = [initial_accuracy]\n",
        "        for epoch in range(n_epochs):\n",
        "            et0 = time.time()\n",
        "            ep_loss = 0\n",
        "            for i_batch, (img_batch, lab_batch) in enumerate(self.train_dl):\n",
        "                img_batch = img_batch.cuda()\n",
        "                lab_batch = lab_batch.cuda()\n",
        "                adv_patch = adv_patch_cpu.cuda()\n",
        "\n",
        "                adv_batch_t = self.patch_transformer(adv_patch, self.img_size, self.batch_size)\n",
        "                p_img_batch = self.patch_applier(img_batch, adv_batch_t)\n",
        "\n",
        "                output = self.model(p_img_batch)\n",
        "                loss = -criterion(output, lab_batch)\n",
        "                ep_loss += loss.detach().cpu().numpy()\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                adv_patch_cpu.data.clamp_(0,1) # keep patch in image range\n",
        "\n",
        "                if i_batch % 20 == 0:\n",
        "                    iteration = self.epoch_length * epoch + i_batch\n",
        "                    print(f\"Epoch {epoch}, batch {i_batch}, iteration {iteration}, loss: {loss.detach().cpu().numpy()}\")\n",
        "\n",
        "            plt.imshow(transforms.ToPILImage()(adv_patch_cpu))\n",
        "            plt.show()\n",
        "\n",
        "            loss_list.append(ep_loss)\n",
        "\n",
        "            val_acc = self.validate(adv_patch_cpu)\n",
        "            val_acc_list.append(val_acc)\n",
        "\n",
        "            scheduler.step(ep_loss)\n",
        "            et1 = time.time()\n",
        "            print('  EPOCH NR: ', epoch),\n",
        "            print('EPOCH LOSS: ', ep_loss)\n",
        "            print('EPOCH TIME: ', et1-et0)\n",
        "            im = transforms.ToPILImage('RGB')(adv_patch_cpu)\n",
        "            plt.imshow(im)\n",
        "            plt.show()\n",
        "            now = datetime.now()\n",
        "            im.save(f\"saved_patches/patch_{now.strftime('%H:%M:%S')}.jpg\")\n",
        "            del adv_batch_t, output, p_img_batch, loss\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        return adv_patch_cpu, loss_list, val_acc_list\n",
        "\n",
        "    def validate(self, adv_patch):\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for i_batch, (img_batch, lab_batch) in enumerate(self.val_dl):\n",
        "            img_batch = img_batch.cuda()\n",
        "            lab_batch = lab_batch.cuda()\n",
        "            adv_patch = adv_patch.cuda()\n",
        "            adv_batch_t = self.patch_transformer(adv_patch, self.img_size, self.batch_size)\n",
        "            p_img_batch = self.patch_applier(img_batch, adv_batch_t)\n",
        "\n",
        "            adv_output = self.model(p_img_batch)\n",
        "            _, predicted = torch.max(adv_output.data, 1)\n",
        "\n",
        "            total += lab_batch.size(0)\n",
        "            correct += (predicted == lab_batch).sum()\n",
        "            \n",
        "        val_acc = correct / len(self.val_dl.dataset)\n",
        "        print(f\"VALIDATION ACCURACY: {val_acc}\")\n",
        "        return val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZiCCtHoPlrH"
      },
      "source": [
        "### Train patch on regular model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7pGZrg8O3Sb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "!mkdir saved_patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOydS5TNEF4p"
      },
      "outputs": [],
      "source": [
        "model_path = \"results/checkpoints/CIFAR10_PGD_PreActResNet-18_Eps8_.pth\"\n",
        "acc_iter = []\n",
        "for i in range(2, 11):\n",
        "    trainer = PatchTrainer(i, model_path, \"cuda\")\n",
        "    adv_patch, loss_list, val_acc_list = trainer.train()\n",
        "    acc_iter.append(val_acc_list[-1])\n",
        "regular_val_acc = list(map(lambda x: x.detach().cpu().item(), acc_iter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TiUQgOvEAdv"
      },
      "outputs": [],
      "source": [
        "model_path = \"results/checkpoints/CIFAR10_FAST_AT_PreActResNet-18_Eps8.0_.pth\"\n",
        "acc_iter = []\n",
        "for i in range(2, 11):\n",
        "    trainer = PatchTrainer(i, model_path, \"cuda\")\n",
        "    adv_patch, loss_list, val_acc_list = trainer.train()\n",
        "    acc_iter.append(val_acc_list[-1])\n",
        "fast_at_val_acc = list(map(lambda x: x.detach().cpu().item(), acc_iter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drXzRh8ErAxH"
      },
      "outputs": [],
      "source": [
        "model_path = \"results/checkpoints/CIFAR10_FAST_BAT_PreActResNet-18_Eps8.0_.pth\"\n",
        "acc_iter = []\n",
        "for i in range(2, 11):\n",
        "    trainer = PatchTrainer(i, model_path, \"cuda\")\n",
        "    adv_patch, loss_list, val_acc_list = trainer.train()\n",
        "    acc_iter.append(val_acc_list[-1])\n",
        "fast_bat_val_acc = list(map(lambda x: x.detach().cpu().item(), acc_iter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5I7HyMhWeAI"
      },
      "outputs": [],
      "source": [
        "!mkdir images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pNZPb4nT6O2"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(range(2, 11, 1), regular_val_acc, label=\"Regular model\")\n",
        "plt.plot(range(2, 11, 1), fast_at_val_acc, label=\"FAST-AT trained model\")\n",
        "plt.plot(range(2, 11, 1), fast_bat_val_acc, label=\"FAST-BAT trained model\")\n",
        "plt.legend()\n",
        "plt.xlabel('size of adversarial patch')\n",
        "plt.ylabel('validation accuracy')\n",
        "plt.title('Comparison of adversarial patch effectiveness')\n",
        "plt.xticks(np.arange(2, 11, 1))\n",
        "plt.savefig('images/adversarial_patch_comparison.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wwhub0Ub4Nv9"
      },
      "source": [
        "### Evaluate results on random patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4q6eSwz4QhG"
      },
      "outputs": [],
      "source": [
        "model_path = \"results/checkpoints/CIFAR10_PGD_PreActResNet-18_Eps8_.pth\"\n",
        "acc_iter = []\n",
        "for i in range(2, 11):\n",
        "    trainer = PatchTrainer(i, model_path, \"cuda\")\n",
        "    random_adv_patch = trainer.generate_patch(\"random\")\n",
        "    val_acc = trainer.validate(random_adv_patch)\n",
        "    acc_iter.append(val_acc)\n",
        "regular_val_acc = list(map(lambda x: x.detach().cpu().item(), acc_iter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peTM2ZHK4nJv"
      },
      "outputs": [],
      "source": [
        "model_path = \"results/checkpoints/CIFAR10_FAST_AT_PreActResNet-18_Eps8.0_.pth\"\n",
        "acc_iter = []\n",
        "for i in range(2, 11):\n",
        "    trainer = PatchTrainer(i, model_path, \"cuda\")\n",
        "    random_adv_patch = trainer.generate_patch(\"random\")\n",
        "    val_acc = trainer.validate(random_adv_patch)\n",
        "    acc_iter.append(val_acc)\n",
        "fast_at_val_acc = list(map(lambda x: x.detach().cpu().item(), acc_iter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma2Y_C8q4v1W"
      },
      "outputs": [],
      "source": [
        "model_path = \"results/checkpoints/CIFAR10_FAST_BAT_PreActResNet-18_Eps8.0_.pth\"\n",
        "acc_iter = []\n",
        "for i in range(2, 11):\n",
        "    trainer = PatchTrainer(i, model_path, \"cuda\")\n",
        "    random_adv_patch = trainer.generate_patch(\"random\")\n",
        "    val_acc = trainer.validate(random_adv_patch)\n",
        "    acc_iter.append(val_acc)\n",
        "fast_bat_val_acc = list(map(lambda x: x.detach().cpu().item(), acc_iter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtTi31SL40g-"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(range(2, 11, 1), regular_val_acc, label=\"Regular model\")\n",
        "plt.plot(range(2, 11, 1), fast_at_val_acc, label=\"FAST-AT trained model\")\n",
        "plt.plot(range(2, 11, 1), fast_bat_val_acc, label=\"FAST-BAT trained model\")\n",
        "plt.legend()\n",
        "plt.xlabel('size of adversarial patch')\n",
        "plt.ylabel('validation accuracy')\n",
        "plt.title('Comparison of random patch effectiveness')\n",
        "plt.xticks(np.arange(2, 11, 1))\n",
        "plt.savefig('images/adversarial_patch_comparison_random.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Julia 1.8.0",
      "language": "julia",
      "name": "julia-1.8"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
